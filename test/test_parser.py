""" Tests for the lexer and parser. """

import sys, sure, os

from metapipe import parser


def test_split_params():
    cmd = 'cut -hf --someflag {1,2,3||1,2||2,3,4}'
    res = parser._split_params(cmd)

    res[0].should.equal(('cut -hf --someflag {in}', ['1','2','3'], []))
    res[1].should.equal(('cut -hf --someflag {in}', ['1','2'], []))
    res[2].should.equal(('cut -hf --someflag {in}', ['2','3','4'], []))


def test_parse_job():
    cmd = 'cut -hf --someflag {1,2,3||1,2||2,3,4}'
    jobs = []
    files = [parser.FileResult('file1', '1'),
            parser.FileResult('file2', '2'),
            parser.FileResult('file3', '3'),
            parser.FileResult('file4', '4')]
    paths=[]

    jobs = parser.parse_job(cmd, jobs, files, paths)

    len(jobs).should.equal(3)
    jobs[0].raw_cmd.should.equal('cut -hf --someflag {in}')

    jobs[0].input_files.should.contain(files[0])
    jobs[1].input_files.should.contain(files[0])
    jobs[2].input_files.shouldnt.contain(files[0])


def test_complex_job():
    cmd = 'cut -hf --someflag {1,2,3||1,2}'
    jobs = []
    files = [parser.FileResult('file1', '1'),
            parser.FileResult('file2', '2'),
            parser.FileResult('file3', '3'),
            parser.FileResult('file4', '4'),
            parser.FileResult('file5', '5')]
    paths=[]

    jobs = parser.parse_job(cmd, jobs, files, paths)

    cmd = 'python somescript -f {o:$INPUT.counts} {2||5}'
    jobs = parser.parse_job(cmd, jobs, files, paths)


    len(jobs).should.equal(4)
    jobs[0].raw_cmd.should.equal('cut -hf --someflag {in}')
    jobs[3].raw_cmd.should.equal('python somescript -f {out} {in}')

    jobs[1].depends_on.should.contain(jobs[0])
    jobs[2].depends_on.should.contain(jobs[0])
    jobs[2].depends_on.should.contain(jobs[1])
    len(jobs[3].depends_on).should.equal(0)



def test_lexer():
    
    test_file_text = """
# Lines beginning with # signs are comments.
# Analyzes Sassafrass files.
# <author>
# TODO: Add Notes.

# These are *magic comments.*
#{CLEANUP}
#{STOP_ON_ERR}
#{NO_RETRY}

# File.Step - Naming convention for files

>COMMANDS:
# Cut all the files listed in the files list and save them to another file.
1. cut -f 1 {||} > {o}

# For each of those files, run a given Python script (each file is
independent).
2. python {1.*||} > {o}

# Once all those files are done, run the analysis on them.
3. htseq -fgt -o {o} {2.*,}

# To get the results, run another script for each .counts file generated by #2.
4. ./analyze_counts -o {o} -i {3.*.counts||}

# For files 1,3,4,5,6,9 run the last step.
5. cat {4.1,4.3-6,4.9} | grep 'sassafrass' | python analyze_sassafrass.py -o {o.finalized}

# You can even reuse files from other steps.
6. cat {4.1,3.2||3.4,5.6||1.1,1} >> somefile

# No explicitly specified output file
7. python blah_blah.py {*.6} {o: *.6.counts }

>FILES:
1: SAMPLE_1.csv
2: SAMPLE_2.csv
3: SAMPLE_3.csv
4: SAMPLE_4.csv
5: SAMPLE_5.csv
Label1: SAMPLE_6.csv
Label2: SAMPLE_7.csv
Label3: SAMPLE_8.csv

>PATHS:
python: python_path
htseq: htseq_path
"""


    named_tuple = parser.lexer(test_file_text)
    named_tuple.cmds.should.contain('1. cut -f 1 {||} > {o}')
    named_tuple.magic.should.contain('#{CLEANUP}')
    named_tuple.files.should.contain('1: SAMPLE_1.csv')
    named_tuple.paths.should.contain('python: python_path')

